### 0. 클라우드 서버의 자원 ( F-Lab 에서 지원 가능한지 여부)
- 매니저 님에게 말씀 드리면 될것.
- 부분 지원 되는 부분을 확인.

### 1. 서버 스펙을 정하는것 부터 ( 생각한 서버 스펙 )
-  

### 2. 성능 측정 재시도
-

### 3. 컨슈머 소비에 대한 측정 시나리오 구성

---

# Kafka 부하 테스트 가이드

## 1. 파티션 수 산정

### 기본 원칙
```
파티션 수 = 최대 동시 소비 단위
파티션 수 ≥ 컨슈머 수 (동일 그룹 내)
```

### 산정 공식
```
1. 목표 TPS 설정 (예: 3,000 TPS)
2. 컨슈머 1개당 처리량 측정 (예: 500 TPS)
3. 필요 컨슈머 수 = 3,000 ÷ 500 = 6개
4. 권장 파티션 수 = 6 × (2~3) = 12~18개
```

## 2. 환경 구성

### 2.1 네트워크 생성
```bash
docker network create fds-net
```

### 2.2 nGrinder 환경 설정
```bash
# 디렉토리 생성
mkdir -p ngrinder/{controller-data,agent-data,userlib}
cd ngrinder

# Kafka 의존성 라이브러리 복사
docker cp transfer-kafka:/opt/bitnami/kafka/libs/kafka-clients-3.7.1.jar ./controller-data/userlib/
docker cp transfer-kafka:/opt/bitnami/kafka/libs/lz4-java-1.8.0.jar ./controller-data/userlib/
docker cp transfer-kafka:/opt/bitnami/kafka/libs/snappy-java-1.1.10.5.jar ./controller-data/userlib/
```

## 3. 부하 테스트 시나리오

### 시나리오 1: 기본 Producer 성능 테스트

```groovy
import net.grinder.script.GTest
import net.grinder.script.Grinder
import net.grinder.scriptengine.groovy.junit.GrinderRunner
import org.junit.Before
import org.junit.Test
import org.junit.runner.RunWith

import org.apache.kafka.clients.producer.*
import org.apache.kafka.common.serialization.StringSerializer
import java.util.concurrent.TimeUnit
import java.util.concurrent.atomic.AtomicLong
import java.util.Random

@RunWith(GrinderRunner)
class KafkaProducerLoadTest {
    
    // 테스트 설정
    public static GTest gTest = new GTest(1, "Kafka Producer Performance Test")
    public static Grinder grinder = Grinder.grinder

    // 시스템 프로퍼티로 설정 가능한 변수들
    static String BOOTSTRAP = System.getProperty("kafka.bootstrap", "kafka:9092")
    static String TOPIC = System.getProperty("kafka.topic", "transfer-events")
    static int TARGET_TPS = Integer.parseInt(System.getProperty("target.tps", "200"))
    static int MESSAGE_SIZE = Integer.parseInt(System.getProperty("message.size", "256"))
    static String KEY_PATTERN = System.getProperty("key.pattern", "uniform")
    static int KEY_SPACE = Integer.parseInt(System.getProperty("key.space", "100000"))

    // Producer 설정
    static Properties producerProps = new Properties()
    static {
        // 기본 설정
        producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP)
        producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName())
        producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.ByteArraySerializer")
        
        // 성능 최적화 설정 (200-2000 TPS 대응)
        producerProps.put(ProducerConfig.ACKS_CONFIG, "1")
        producerProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "false")
        producerProps.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, "5")
        producerProps.put(ProducerConfig.LINGER_MS_CONFIG, "5")
        producerProps.put(ProducerConfig.BATCH_SIZE_CONFIG, Integer.toString(64 * 1024))
        producerProps.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "lz4")
        producerProps.put(ProducerConfig.BUFFER_MEMORY_CONFIG, Integer.toString(64 * 1024 * 1024))
        
        // 재시도 설정
        producerProps.put(ProducerConfig.RETRIES_CONFIG, "3")
        producerProps.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, "30000")
    }

    static Producer<String, byte[]> producer
    static Random random = new Random()
    static AtomicLong messagesSent = new AtomicLong(0)
    static AtomicLong bytessSent = new AtomicLong(0)

    @Before
    public void setUp() {
        if (producer == null) {
            producer = new KafkaProducer<>(producerProps)
            grinder.logger.info("Kafka Producer initialized. Target TPS: ${TARGET_TPS}")
        }
        gTest.record(this, "sendMessage")
    }

    @Test
    public void runLoadTest() {
        long startTime = System.currentTimeMillis()
        
        // 1초 동안 TARGET_TPS만큼 메시지 전송
        for (int i = 0; i < TARGET_TPS; i++) {
            sendMessage()
            
            // TPS 조절을 위한 간격 계산
            if (i % 10 == 0) {
                long elapsed = System.currentTimeMillis() - startTime
                long expectedTime = (long) (i * 1000.0 / TARGET_TPS)
                if (elapsed < expectedTime) {
                    Thread.sleep(expectedTime - elapsed)
                }
            }
        }
        
        // 남은 시간 대기 (정확한 1초 주기 유지)
        long totalElapsed = System.currentTimeMillis() - startTime
        if (totalElapsed < 1000) {
            Thread.sleep(1000 - totalElapsed)
        }
    }

    public void sendMessage() {
        // 키 생성 전략
        String key = generateKey()
        
        // 메시지 생성 (Transfer 이벤트 시뮬레이션)
        byte[] message = generateTransferMessage()
        
        // 비동기 전송
        producer.send(new ProducerRecord<>(TOPIC, key, message)) { metadata, exception ->
            if (exception == null) {
                messagesSent.incrementAndGet()
                bytessSent.addAndGet(message.length)
                grinder.statistics.forLastTest.success = 1
            } else {
                grinder.logger.error("Send failed: ${exception.message}")
                grinder.statistics.forLastTest.success = 0
            }
        }
    }

    private String generateKey() {
        switch (KEY_PATTERN) {
            case "sequential":
                return "key-${messagesSent.get()}"
            case "random":
                return "key-${random.nextInt(KEY_SPACE)}"
            case "uniform":
            default:
                return "transfer-${random.nextInt(KEY_SPACE)}"
        }
    }

    private byte[] generateTransferMessage() {
        // Transfer 이벤트 JSON 시뮬레이션
        String json = """
        {
            "eventType": "TRANSFER_COMPLETED",
            "transactionId": ${random.nextLong()},
            "senderId": ${random.nextInt(10000)},
            "receiverId": ${random.nextInt(10000)},
            "amount": ${random.nextInt(1000000)},
            "timestamp": ${System.currentTimeMillis()},
            "traceId": "trace-${random.nextInt(100000)}"
        }
        """.trim()
        
        // 메시지 크기 조정
        byte[] baseMessage = json.getBytes("UTF-8")
        if (baseMessage.length < MESSAGE_SIZE) {
            // 패딩 추가
            byte[] padding = new byte[MESSAGE_SIZE - baseMessage.length]
            Arrays.fill(padding, (byte) 'X')
            byte[] result = new byte[MESSAGE_SIZE]
            System.arraycopy(baseMessage, 0, result, 0, baseMessage.length)
            System.arraycopy(padding, 0, result, baseMessage.length, padding.length)
            return result
        }
        
        return baseMessage
    }
}
```

### 시나리오 2: Consumer 성능 측정

```groovy
// Consumer 처리량 측정용 (별도 테스트)
// 1개 컨슈머가 초당 몇 건 처리 가능한지 측정
```

## 4. 테스트 실행 절차

### 4.1 사전 준비

```bash
# 1. 네트워크 및 Kafka 실행 상태 확인
docker network ls | grep fds-net
docker exec -it ngrinder-agent nc -vz kafka 9092

# 2. 라이브러리 확인
ls ./controller-data/userlib/
# 출력 예상: kafka-clients-3.7.1.jar lz4-java-1.8.0.jar snappy-java-1.1.10.5.jar

# 3. Agent에서 라이브러리 로드 확인
docker exec -it ngrinder-agent ls /opt/ngrinder-agent/lib | egrep 'kafka|lz4|snappy'
```

### 4.2 테스트 시나리오별 실행

**A. 기본 성능 테스트 (200 TPS)**
```
Target TPS: 200
Message Size: 256 bytes
Duration: 10 minutes
Virtual Users: 10
Ramp-up: 30 seconds
```

**B. 피크 부하 테스트 (2000 TPS)**
```
Target TPS: 2000  
Message Size: 256 bytes
Duration: 5 minutes
Virtual Users: 50
Ramp-up: 60 seconds
```

**C. 대용량 메시지 테스트**
```
Target TPS: 100
Message Size: 2048 bytes
Duration: 5 minutes
```

## 5. 모니터링 및 검증

### 5.1 실시간 로그 확인

```bash
# nGrinder Controller 로그
docker logs --tail=200 -f ngrinder-controller

# Agent 로그
docker logs -f ngrinder-agent

# 최신 테스트 로그 확인
docker exec -it ngrinder-agent sh -lc "ls -1t /opt/ngrinder-agent/.ngrinder-agent/log | grep -E '^test_' | head -n 1"
```

### 5.2 Kafka 메트릭 확인

```bash
# Kafka Topic 정보 확인
docker exec -it transfer-kafka kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic transfer-events

# Consumer Group 지연 확인  
docker exec -it transfer-kafka kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups
```

## 6. 트러블슈팅

### 6.1 라이브러리 문제

```bash
# 라이브러리 강제 복사
docker cp ./controller-data/userlib/kafka-clients-3.7.1.jar ngrinder-agent:/opt/ngrinder-agent/lib/
docker cp ./controller-data/userlib/lz4-java-1.8.0.jar ngrinder-agent:/opt/ngrinder-agent/lib/
docker cp ./controller-data/userlib/snappy-java-1.1.10.5.jar ngrinder-agent:/opt/ngrinder-agent/lib/

# Agent 재시작
docker restart ngrinder-agent
```

### 6.2 네트워크 연결 문제

```bash
# Kafka 연결 확인
docker exec -it ngrinder-agent nc -vz kafka 9092

# DNS 해결 확인
docker exec -it ngrinder-agent nslookup kafka
```

### 6.3 성능 튜닝 체크포인트

**Producer 설정 최적화:**
- `linger.ms`: 5ms (지연 vs 배치 크기 균형)
- `batch.size`: 64KB (대용량 배치)
- `compression.type`: lz4 (빠른 압축)
- `acks`: 1 (성능 우선시)

**Consumer 설정 최적화:**
- `fetch.max.wait.ms`: 100ms
- `max.poll.records`: 1000
- `session.timeout.ms`: 30000

## 7. 결과 분석 가이드

### 7.1 성능 지표

```
목표 달성률 = (실제 TPS / 목표 TPS) × 100%
평균 응답시간 < 10ms (Producer)
에러율 < 0.1%
CPU 사용률 < 80%
메모리 사용률 < 70%
```

### 7.2 파티션 수 재계산

```
실제 측정된 컨슈머 처리량을 기반으로:
- 1개 컨슈머 처리량: X TPS
- 목표 처리량: Y TPS  
- 필요 컨슈머 수: Y ÷ X
- 권장 파티션 수: (Y ÷ X) × 2
```